{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LJMfintech/Financial_Data_Analysis_2/blob/main/DataAnalysisHW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyPLI0bM6SZG",
        "outputId": "668938cd-9eaa-4fa7-d836-d2443ff113a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wrds in /usr/local/lib/python3.12/dist-packages (3.4.0)\n",
            "Requirement already satisfied: packaging<=24.2 in /usr/local/lib/python3.12/dist-packages (from wrds) (24.2)\n",
            "Requirement already satisfied: pandas<2.3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from wrds) (2.2.2)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.12/dist-packages (from wrds) (2.9.11)\n",
            "Requirement already satisfied: sqlalchemy<2.1,>=2 in /usr/local/lib/python3.12/dist-packages (from wrds) (2.0.44)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3,>=2.2->wrds) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3,>=2.2->wrds) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3,>=2.2->wrds) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3,>=2.2->wrds) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<2.1,>=2->wrds) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<2.1,>=2->wrds) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.17.0)\n",
            "Requirement already satisfied: numpy_financial in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from numpy_financial) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wrds\n",
        "!pip install numpy_financial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgJoUvOA6rXJ"
      },
      "outputs": [],
      "source": [
        "# 코드를 작성하는데 필요한 도구들 끌어오기\n",
        "import wrds\n",
        "import numpy_financial as npf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F091j13E6um8",
        "outputId": "370ddd33-ab0f-4a4e-ea15-8b27b0985db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your WRDS username [root]:leeskku2025\n",
            "Enter your password:··········\n",
            "WRDS recommends setting up a .pgpass file.\n",
            "Create .pgpass file now [y/n]?: y\n",
            "Created .pgpass file successfully.\n",
            "You can create this file yourself at any time with the create_pgpass_file() function.\n",
            "Loading library list...\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# WRDS 연결\n",
        "conn = wrds.Connection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXVsMrZy6xjB",
        "outputId": "55b5347d-2537-4406-8b01-c8925bde00a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "['aha_sample', 'ahasamp', 'audit', 'audit_audit_comp', 'audit_common', 'auditsmp', 'auditsmp_all', 'bank', 'bank_all', 'bank_premium_samp', 'banksamp', 'block', 'block_all', 'boardex_trial', 'boardsmp', 'bvd_amadeus_trial', 'bvd_bvdbankf_trial', 'bvd_orbis_trial', 'bvdsamp', 'calcbench_trial', 'calcbnch', 'candid_samp', 'cboe', 'cboe_all', 'cboe_sample', 'cboesamp', 'cddsamp', 'ciq', 'ciq_capstrct', 'ciq_common', 'ciqsamp', 'ciqsamp_capstrct', 'ciqsamp_common', 'ciqsamp_keydev', 'ciqsamp_pplintel', 'ciqsamp_ratings', 'ciqsamp_transactions', 'ciqsamp_transcripts', 'cisdmsmp', 'columnar', 'comp', 'comp_execucomp', 'comp_global_daily', 'comp_na_daily_all', 'compsamp', 'compsamp_all', 'compsamp_snapshot', 'contrib', 'contrib_as_filed_financials', 'contrib_ceo_turnover', 'contrib_char_returns', 'contrib_corporate_culture', 'contrib_general', 'contrib_global_factor', 'contrib_intangible_value', 'contrib_kpss', 'contrib_liva', 'crsp', 'crsp_a_indexes', 'crsp_a_stock', 'crsp_a_treasuries', 'crsp_q_indexhist', 'crsp_q_mutualfunds', 'crspsamp', 'crspsamp_all', 'crspsamp_mf', 'csmsamp_all', 'djones', 'djones_all', 'dmef', 'dmef_all', 'doe', 'doe_all', 'etfg_samp', 'etfgsamp', 'execcomp', 'factsamp_all', 'factsamp_revere', 'ff', 'ff_all', 'fisdsamp', 'fisdsamp_all', 'fjc', 'fjc_linking', 'fjc_litigation', 'frb', 'frb_all', 'fssamp', 'ftsesamp', 'ftsesamp_russell_us', 'gutenberg', 'hfrsamp', 'hfrsamp_hfrdb', 'ibes', 'ibessamp_kpi', 'ifgrsamp', 'ims_obp_trial', 'imssamp', 'infasamp', 'infogroupsamp_business', 'infogroupsamp_residential', 'infraclear_samp', 'insdsamp', 'iri', 'iri_all', 'issm', 'issm_nasd1987', 'issm_nasd1988', 'issm_nasd1989', 'issm_nasd1990', 'issm_nasd1991', 'issm_nasd1992', 'issm_nyam1983', 'issm_nyam1984', 'issm_nyam1985', 'issm_nyam1986', 'issm_nyam1987', 'issm_nyam1988', 'issm_nyam1989', 'issm_nyam1990', 'issm_nyam1991', 'issm_nyam1992', 'kpisamp', 'macrofin', 'macrofin_comm_trade', 'midas', 'morningstarsamp_cisdm', 'mpsych_sample', 'mrktsamp', 'mrktsamp_cds', 'mrktsamp_cdx', 'mrktsamp_msf', 'msci_esg_samp', 'msciesmp', 'msrb', 'msrb_all', 'msrbsamp', 'msrbsamp_all', 'omtrial', 'optionmsamp_europe', 'optionmsamp_us', 'otc', 'otc_endofday', 'phlx', 'phlx_all', 'pitchsmp', 'preqsamp', 'preqsamp_all', 'public', 'public_all', 'pwt', 'pwt_all', 'ravenpack_trial', 'reprisk_sample', 'repsamp', 'revelio_samp', 'revsamp', 'risksamp', 'risksamp_all', 'rpnasamp', 'rq_all', 'rstat_samp', 'rstatsmp', 'sdcsamp', 'secsamp', 'secsamp_all', 'shvlsamp', 'snapsamp', 'snlsamp', 'snlsamp_fig', 'sustainalyticssamp_all', 'sustsamp', 'taqmsamp', 'taqmsamp_all', 'taqsamp', 'taqsamp_all', 'tfn', 'totalq', 'totalq_all', 'tr_common', 'tr_ibes', 'tr_mutualfunds', 'tr_sdc_samples', 'trace', 'trace_enhanced', 'trace_standard', 'trcommon', 'trcstsmp', 'trdbdmismp', 'trdbwbsmp', 'trdssamp', 'tresgsmp', 'trsamp', 'trsamp_all', 'trsamp_db_dmi', 'trsamp_db_wb', 'trsamp_ds_eq', 'trsamp_dscom', 'trsamp_dsecon', 'trsamp_dsfut', 'trsamp_esg', 'trsamp_sdc_ma', 'trsamp_sdc_ni', 'trsamp_worldscope', 'trucost_samp', 'twoiq_samp', 'twoiqsmp', 'wappsamp', 'wenvsmp', 'wmfsmp', 'wrds_environmental_samp', 'wrds_insiders_samp', 'wrds_lib_internal', 'wrds_mutualfund_samp', 'wrds_shortvolume_samp', 'wrdsapps', 'wrdsapps_eushort', 'wrdsapps_evtstudy_int', 'wrdsapps_evtstudy_us', 'wrdsapps_finratio', 'wrdsapps_finratio_ibes', 'wrdsapps_link_comp_eushort', 'wrdsapps_link_crsp_bond', 'wrdsapps_link_crsp_factset', 'wrdsapps_link_crsp_ibes', 'wrdsapps_link_crsp_taq', 'wrdsapps_patents', 'wrdsapps_subsidiary', 'wrdsapps_windices', 'wrdsappssamp_all', 'wrdssec_midas', 'zacksamp', 'zacksamp_all']\n"
          ]
        }
      ],
      "source": [
        "# WRDS에 있는 리스트 확인\n",
        "lib_list = conn.list_libraries()\n",
        "print(type(lib_list))\n",
        "print(lib_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BIJseE8K7y8G",
        "outputId": "4f15d0a4-26df-443a-89c6-8201253a8e92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dd_group',\n",
              " 'dd_group_xref',\n",
              " 'dd_item',\n",
              " 'dd_package',\n",
              " 'g_bmiindex',\n",
              " 'g_bmiindexdlynumvalue',\n",
              " 'g_bmiindexidentifier',\n",
              " 'g_bmiindexrel',\n",
              " 'g_bmiindextradingitem',\n",
              " 'g_chars',\n",
              " 'g_co_aaudit',\n",
              " 'g_co_adesind',\n",
              " 'g_co_afnd1',\n",
              " 'g_co_afnd2',\n",
              " 'g_co_afnddc1',\n",
              " 'g_co_afnddc2',\n",
              " 'g_co_afntind1',\n",
              " 'g_co_afntind2',\n",
              " 'g_co_ainvval',\n",
              " 'g_co_gsuppl',\n",
              " 'g_co_hgic',\n",
              " 'g_co_iaudit',\n",
              " 'g_co_idesind',\n",
              " 'g_co_ifndq',\n",
              " 'g_co_ifndsa',\n",
              " 'g_co_ifndytd',\n",
              " 'g_co_ifntq',\n",
              " 'g_co_ifntsa',\n",
              " 'g_co_ifntytd',\n",
              " 'g_co_industry',\n",
              " 'g_co_ipcd',\n",
              " 'g_co_offtitl',\n",
              " 'g_company',\n",
              " 'g_currency',\n",
              " 'g_ecind_desc',\n",
              " 'g_ecind_mth',\n",
              " 'g_exrt_dly',\n",
              " 'g_exrt_mth',\n",
              " 'g_funda',\n",
              " 'g_funda_fncd',\n",
              " 'g_fundq',\n",
              " 'g_fundq_fncd',\n",
              " 'g_idx_daily',\n",
              " 'g_idx_index',\n",
              " 'g_idx_mth',\n",
              " 'g_idxcst_his',\n",
              " 'g_indexcst_his',\n",
              " 'g_names',\n",
              " 'g_names_ix',\n",
              " 'g_names_ix_cst',\n",
              " 'g_namesq',\n",
              " 'g_sec_adesind',\n",
              " 'g_sec_adjfact',\n",
              " 'g_sec_afnd',\n",
              " 'g_sec_afnddc',\n",
              " 'g_sec_afnt',\n",
              " 'g_sec_divid',\n",
              " 'g_sec_dprc',\n",
              " 'g_sec_dtrt',\n",
              " 'g_sec_gmdivfn',\n",
              " 'g_sec_gmth',\n",
              " 'g_sec_gmthdiv',\n",
              " 'g_sec_gmthprc',\n",
              " 'g_sec_history',\n",
              " 'g_sec_idesind',\n",
              " 'g_sec_ifnd',\n",
              " 'g_sec_ifnt',\n",
              " 'g_sec_split',\n",
              " 'g_secd',\n",
              " 'g_secm',\n",
              " 'g_secnamesd',\n",
              " 'g_security',\n",
              " 'g_sedolgvkey',\n",
              " 'g_tmptable_pkg6775_tbl5551',\n",
              " 'gsecnamesm',\n",
              " 'r_accstd',\n",
              " 'r_acqmeth',\n",
              " 'r_auditors',\n",
              " 'r_auopic',\n",
              " 'r_balpres',\n",
              " 'r_cf_formt',\n",
              " 'r_co_status',\n",
              " 'r_coindpre',\n",
              " 'r_compstat',\n",
              " 'r_consol',\n",
              " 'r_country',\n",
              " 'r_cstclscd',\n",
              " 'r_datacode',\n",
              " 'r_datafmt',\n",
              " 'r_divtaxmarker',\n",
              " 'r_docsrce',\n",
              " 'r_ex_codes',\n",
              " 'r_exchgtier',\n",
              " 'r_exrt_typ',\n",
              " 'r_fndfntcd',\n",
              " 'r_footnts',\n",
              " 'r_foricd',\n",
              " 'r_giccd',\n",
              " 'r_hcalendr',\n",
              " 'r_idxclscd',\n",
              " 'r_inactvcd',\n",
              " 'r_incstats',\n",
              " 'r_indfmt',\n",
              " 'r_indsec',\n",
              " 'r_invval',\n",
              " 'r_issuetyp',\n",
              " 'r_majidxcl',\n",
              " 'r_mic_codes',\n",
              " 'r_naiccd',\n",
              " 'r_notetype',\n",
              " 'r_ntsubtype',\n",
              " 'r_offcrso',\n",
              " 'r_ogmethod',\n",
              " 'r_opinions',\n",
              " 'r_prc_stat',\n",
              " 'r_qsrcdoc',\n",
              " 'r_sec_stat',\n",
              " 'r_secannfn',\n",
              " 'r_sectors',\n",
              " 'r_siccd',\n",
              " 'r_spiicd',\n",
              " 'r_spmicd',\n",
              " 'r_statalrt',\n",
              " 'r_states',\n",
              " 'r_stko',\n",
              " 'r_titles',\n",
              " 'r_updates',\n",
              " 'wrds_g_exrate',\n",
              " 'xfl_column',\n",
              " 'xfl_table']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# comp 카테고리하위 리스트 확인.\n",
        "conn.list_tables(library='comp_global_daily')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XXXxVJKS8EjW",
        "outputId": "15fa5637-d1b5-48b4-fa25-c9302e221bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            conm  gvkeyx idx13key idxcstflg  \\\n",
            "0                                   Jasdaq Index  115114  I192948         Y   \n",
            "1                     Malta Stock Exchange Index  115118  I192956         N   \n",
            "2                    Affarsvarlden General Index  150001  I000234         N   \n",
            "3                     Banco Totta & Acores Index  150002  I000220         N   \n",
            "4                            BCI All-Share Index  150003  I000090         N   \n",
            "..                                           ...     ...      ...       ...   \n",
            "730           FTSE AIM All-Share Utilities Index  277876  I220130         N   \n",
            "731          FTSE AIM All-Share Technology Index  277873  I220124         N   \n",
            "732  FTSE AIM All-Share Telecommunications Index  277874  I220126         N   \n",
            "733    FTSE AIM All-Share Travel & Leisure Index  277875  I220128         N   \n",
            "734                     ASX ALL ORDINARIES ACCUM  151333  I261044         N   \n",
            "\n",
            "    idxstat indexcat indexgeo indexid  indextype   indexval  spii  spmi  \\\n",
            "0         A    EXCHG      JPN  JASDAQ  COMPOSITE     JASDAQ  <NA>  <NA>   \n",
            "1         A    EXCHG      MLT     MLT  COMPOSITE        MLT  <NA>  <NA>   \n",
            "2         A    EXCHG      SWE     SWE  COMPOSITE        SWE  <NA>  <NA>   \n",
            "3         I    EXCHG      PRT     PRT  COMPOSITE        PRT  <NA>  <NA>   \n",
            "4         A    EXCHG      ITA     BCI  COMPOSITE        BCI  <NA>  <NA>   \n",
            "..      ...      ...      ...     ...        ...        ...   ...   ...   \n",
            "730       A       FT      GBR     AIM     SECTOR    UTILITY  <NA>  <NA>   \n",
            "731       A       FT      GBR     AIM     SECTOR       TECH  <NA>  <NA>   \n",
            "732       A       FT      GBR     AIM     SECTOR    TELECOM  <NA>  <NA>   \n",
            "733       A       FT      GBR     AIM     SECTOR     TRALEI  <NA>  <NA>   \n",
            "734       A    EXCHG      AUS     ASX  COMPOSITE  ASXALLACC  <NA>  <NA>   \n",
            "\n",
            "          tic      tici  \n",
            "0    I2JPN017  I2JPN017  \n",
            "1    I3MLT002  I3MLT002  \n",
            "2    I3SWE001  I3SWE001  \n",
            "3    I3PRT001  I3PRT001  \n",
            "4    I3ITA002  I3ITA002  \n",
            "..        ...       ...  \n",
            "730  I3GBR117  I3GBR117  \n",
            "731  I3GBR114  I3GBR114  \n",
            "732  I3GBR115  I3GBR115  \n",
            "733  I3GBR116  I3GBR116  \n",
            "734  I2AUS011  I2AUS011  \n",
            "\n",
            "[735 rows x 14 columns]\n"
          ]
        }
      ],
      "source": [
        "# 테이블 선정\n",
        "test1 = conn.get_table(library='comp_global_daily', table='g_idx_index')\n",
        "print(test1)\n",
        "\n",
        "# test1\n",
        "test1.to_csv('test1.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3wz0KZQGByn",
        "outputId": "7575644a-efc7-49cc-e607-ff5b4a804309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   gvkeyx dvpsxd newnum oldnum  prccd prccddiv prccddivn prchd prcld  \\\n",
            "0  115114   <NA>   <NA>   <NA>  96.41     <NA>      <NA>  <NA>  <NA>   \n",
            "1  115114   <NA>   <NA>   <NA>  79.21     <NA>      <NA>  <NA>  <NA>   \n",
            "2  115114   <NA>   <NA>   <NA>  72.52     <NA>      <NA>  <NA>  <NA>   \n",
            "3  115114   <NA>   <NA>   <NA>  71.61     <NA>      <NA>  <NA>  <NA>   \n",
            "4  115114   <NA>   <NA>   <NA>  71.71     <NA>      <NA>  <NA>  <NA>   \n",
            "\n",
            "     datadate  \n",
            "0  1991-10-31  \n",
            "1  1991-11-30  \n",
            "2  1991-12-31  \n",
            "3  1992-01-31  \n",
            "4  1992-02-28  \n"
          ]
        }
      ],
      "source": [
        "test2 = conn.get_table(library='comp_global_daily', table='g_idx_daily', obs = 5)\n",
        "# test1\n",
        "print(test2.head())\n",
        "test2.to_csv('test2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4xBDPxWKdS_",
        "outputId": "20a9a0dc-fd19-4383-b7b4-15a6d1b20f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   gvkeyx   prccd    datadate\n",
            "0  150011  682.94  1985-12-31\n",
            "1  150011  682.94  1986-01-01\n",
            "2  150011  686.62  1986-01-02\n",
            "3  150011   690.8  1986-01-03\n",
            "4  150011  689.86  1986-01-06\n",
            "(10404, 3)\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "data_set = conn.raw_sql(\"\"\"select gvkeyx, prccd, datadate\n",
        "\n",
        "                          from comp_global_daily.g_idx_daily\n",
        "                          where gvkeyx IN('150011')\n",
        "                          \"\"\")\n",
        "print(data_set.head())    # and datadate between '2020-03-01' and '2024-12-31'\n",
        "print(data_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcUSLUIa8Tzf"
      },
      "outputs": [],
      "source": [
        "data_set.to_csv('data_set.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MmaGKn9ISm0",
        "outputId": "f33d9126-fbc1-482e-a239-2af987a488d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   gvkeyx   prccd    datadate    return\n",
            "0  150011  682.94  1985-12-31       NaN\n",
            "1  150011  682.94  1986-01-01  0.000000\n",
            "2  150011  686.62  1986-01-02  0.005388\n",
            "3  150011  690.80  1986-01-03  0.006088\n",
            "4  150011  689.86  1986-01-06 -0.001361\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "df = pd.read_csv('data_set.csv')\n",
        "\n",
        "# prccd 컬럼이 있는지 확인 후 수익률 계산 및 추가\n",
        "def add_returns_to_df(df, price_col='prccd', return_col='return'):\n",
        "    df[return_col] = df[price_col].pct_change()\n",
        "    return df\n",
        "\n",
        "df_returns = add_returns_to_df(df)\n",
        "print(df_returns.head())\n",
        "\n",
        "df_returns.to_csv('df_returns.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "qALVWVrzNYCK",
        "outputId": "297a499e-ebcb-41cf-f182-b4a5d529b236"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d1f79784-b102-44d0-ab9d-fb92237bb8b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d1f79784-b102-44d0-ab9d-fb92237bb8b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dwcountryreturns.csv to dwcountryreturns.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() # dwcountreturns 파일 업로드 하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7yBYJc-JfbC",
        "outputId": "cffce4e8-fb98-4cf9-b3b2-9035a51e8131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    datadate    country  fic    n currency    return   portret  portretx  \\\n",
            "0 1986-07-01  AUSTRALIA  AUS   54      AUD  0.005615 -0.001796 -0.001796   \n",
            "1 1986-07-01    DENMARK  DNK   14      DKK  0.005615  0.012794  0.012794   \n",
            "2 1986-07-01  HONG KONG  HKG   16      HKD  0.005615 -0.000580 -0.000580   \n",
            "3 1986-07-01      JAPAN  JPN  638      JPY  0.005615 -0.003055 -0.003055   \n",
            "4 1986-07-01  SINGAPORE  SGP   17      SGD  0.005615  0.009316  0.009316   \n",
            "\n",
            "    prccd  \n",
            "0  820.28  \n",
            "1  820.28  \n",
            "2  820.28  \n",
            "3  820.28  \n",
            "4  820.28  \n"
          ]
        }
      ],
      "source": [
        "# 기존 파일들 불러오기\n",
        "df_returns = pd.read_csv('df_returns.csv')  # data_set에서 수익률이 포함된 파일\n",
        "dwcountryreturns = pd.read_csv('dwcountryreturns.csv')  # 병합할 큰 파일\n",
        "\n",
        "# datadate 컬럼을 datetime 타입으로 변환\n",
        "df_returns['datadate'] = pd.to_datetime(df_returns['datadate'])\n",
        "# dwcountryreturns['datadate'] = pd.to_datetime(dwcountryreturns['datadate'])\n",
        "dwcountryreturns['datadate'] = pd.to_datetime(dwcountryreturns['datadate'].astype(str), format='%Y%m%d', errors='coerce')\n",
        "\n",
        "# datadate 기준으로 내부 조인 (inner join) 하여 병합\n",
        "df_merged = pd.merge(df_returns, dwcountryreturns, on='datadate', how='inner')\n",
        "\n",
        "\n",
        "# 결측치가 포함된 행 모두 삭제\n",
        "df_merged_clean = df_merged.dropna()\n",
        "\n",
        "new_order = [\n",
        "    'datadate', 'country', 'fic', 'n', 'currency',\n",
        "    'return', 'portret', 'portretx', 'prccd'\n",
        "]\n",
        "\n",
        "df_merged_clean = df_merged_clean[new_order]\n",
        "\n",
        "# 결과 확인 (예: 상위 5개 행)\n",
        "print(df_merged_clean.head())\n",
        "\n",
        "df_merged_clean.to_csv('df_merged_clean.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "fPgYb934TD5J",
        "outputId": "dfe1da68-71ca-4a16-f9c7-4b4400986ccd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-267822c5-4dfd-45d2-b05a-53f20fd82b9c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-267822c5-4dfd-45d2-b05a-53f20fd82b9c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nsshock.csv to nsshock.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() # nsshock 올리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Eft5ma6fSMpJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "da4f2f3e-55d7-4ccf-c100-d22a24618d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1] 기존 데이터 불러오기...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4138970552.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 이미 준비된 국가별 일별 수익률 데이터\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_merged_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_merged_clean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf_merged_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_merged_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# nsshock 데이터 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "\n",
        "# ====================================================================\n",
        "# STEP 1: 기존 데이터 불러오기\n",
        "# ====================================================================\n",
        "print(\"[Step 1] 기존 데이터 불러오기...\")\n",
        "\n",
        "# 이미 준비된 국가별 일별 수익률 데이터\n",
        "df_merged_clean = pd.read_csv('df_merged_clean.csv')\n",
        "df_merged_clean['date'] = pd.to_datetime(df_merged_clean['date'])\n",
        "\n",
        "# nsshock 데이터 불러오기\n",
        "nsshock = pd.read_csv('nsshock.csv')\n",
        "nsshock['date'] = pd.to_datetime(nsshock['date'])\n",
        "\n",
        "print(f\"✓ df_merged_clean 데이터: {len(df_merged_clean)} 행\")\n",
        "print(f\"  컬럼: {df_merged_clean.columns.tolist()}\")\n",
        "print(f\"✓ nsshock 데이터: {len(nsshock)} 행\")\n",
        "print(nsshock.head())\n",
        "\n",
        "# 국가별 시차 정보 (0: 당일, 1: 1일 뒤)\n",
        "country_time_lag = {\n",
        "    'AUSTRALIA': 1,\n",
        "    'AUSTRIA': 1,\n",
        "    'BELGIUM': 1,\n",
        "    'BRAZIL': 0,\n",
        "    'SWITZERLAND': 1,\n",
        "    'CHILE': 0,\n",
        "    'CHINA': 1,\n",
        "    'COLOMBIA': 0,\n",
        "    'GERMANY': 1,\n",
        "    'DENMARK': 1,\n",
        "    'EGYPT': 1,\n",
        "    'SPAIN': 1,\n",
        "    'FINLAND': 1,\n",
        "    'FRANCE': 1,\n",
        "    'UNITED KINGDOM': 1,\n",
        "    'GREECE': 1,\n",
        "    'HONG KONG': 1,\n",
        "    'HUNGARY': 1,\n",
        "    'INDONESIA': 1,\n",
        "    'INDIA': 1,\n",
        "    'IRELAND': 1,\n",
        "    'ITALY': 1,\n",
        "    'JAPAN': 1,\n",
        "    'SOUTH KOREA': 1,\n",
        "    'MEXICO': 0,\n",
        "    'MALAYSIA': 1,\n",
        "    'NETHERLANDS': 1,\n",
        "    'NORWAY': 1,\n",
        "    'NEW ZEALAND': 1,\n",
        "    'PHILIPPINES': 1,\n",
        "    'POLAND': 1,\n",
        "    'PORTUGAL': 1,\n",
        "    'SINGAPORE': 1,\n",
        "    'SWEDEN': 1,\n",
        "    'THAILAND': 1,\n",
        "    'TURKEY': 1,\n",
        "    'TAIWAN': 1,\n",
        "    'SOUTH AFRICA': 1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "\n",
        "# ====================================================================\n",
        "# STEP 1: 기존 데이터 불러오기\n",
        "# ====================================================================\n",
        "print(\"[Step 1] 기존 데이터 불러오기...\")\n",
        "\n",
        "# 이미 준비된 국가별 일별 수익률 데이터\n",
        "df_merged_clean = pd.read_csv('df_merged_clean.csv')\n",
        "df_merged_clean['datadate'] = pd.to_datetime(df_merged_clean['datadate'])\n",
        "\n",
        "# nsshock 데이터 불러오기\n",
        "nsshock = pd.read_csv('nsshock.csv')\n",
        "nsshock['datadate'] = pd.to_datetime(nsshock['datadate'])\n",
        "\n",
        "print(f\"✓ df_merged_clean 데이터: {len(df_merged_clean)} 행\")\n",
        "print(f\"  컬럼: {df_merged_clean.columns.tolist()}\")\n",
        "print(f\"✓ nsshock 데이터: {len(nsshock)} 행\")\n",
        "print(nsshock.head())\n",
        "\n",
        "# ====================================================================\n",
        "# STEP 2: 국가별 시차 정의 (타임존 조정)\n",
        "# ====================================================================\n",
        "print(\"\\n[Step 2] 국가별 시차 정의...\")\n",
        "\n",
        "country_time_lag = {\n",
        "    'AUSTRALIA': 1,\n",
        "    'AUSTRIA': 1,\n",
        "    'BELGIUM': 1,\n",
        "    'BRAZIL': 0,\n",
        "    'SWITZERLAND': 1,\n",
        "    'CHILE': 0,\n",
        "    'CHINA': 1,\n",
        "    'COLOMBIA': 0,\n",
        "    'GERMANY': 1,\n",
        "    'DENMARK': 1,\n",
        "    'EGYPT': 1,\n",
        "    'SPAIN': 1,\n",
        "    'FINLAND': 1,\n",
        "    'FRANCE': 1,\n",
        "    'UNITED KINGDOM': 1,\n",
        "    'GREECE': 1,\n",
        "    'HONG KONG': 1,\n",
        "    'HUNGARY': 1,\n",
        "    'INDONESIA': 1,\n",
        "    'INDIA': 1,\n",
        "    'IRELAND': 1,\n",
        "    'ITALY': 1,\n",
        "    'JAPAN': 1,\n",
        "    'SOUTH KOREA': 1,\n",
        "    'MEXICO': 0,\n",
        "    'MALAYSIA': 1,\n",
        "    'NETHERLANDS': 1,\n",
        "    'NORWAY': 1,\n",
        "    'NEW ZEALAND': 1,\n",
        "    'PHILIPPINES': 1,\n",
        "    'POLAND': 1,\n",
        "    'PORTUGAL': 1,\n",
        "    'SINGAPORE': 1,\n",
        "    'SWEDEN': 1,\n",
        "    'THAILAND': 1,\n",
        "    'TURKEY': 1,\n",
        "    'TAIWAN': 1,\n",
        "    'SOUTH AFRICA': 1,\n",
        "}\n",
        "\n",
        "print(f\"✓ 정의된 국가 수: {len(country_time_lag)}\")\n",
        "\n",
        "# ====================================================================\n",
        "# STEP 3: 타임존 조정을 고려한 병합 함수\n",
        "# ====================================================================\n",
        "print(\"\\n[Step 3] 병합 함수 정의...\")\n",
        "\n",
        "def merge_shock_with_time_lag(returns_df, shock_df, time_lag_map, event_window_days=5):\n",
        "    \"\"\"\n",
        "    타임존을 고려하여 NS Shock을 수익률 데이터에 병합\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    returns_df : DataFrame\n",
        "        국가별 일별 수익률 데이터 (datadate, country, return, benchmark_return 등 포함)\n",
        "    shock_df : DataFrame\n",
        "        NS Shock 데이터 (datadate, NS_shock 포함)\n",
        "    time_lag_map : dict\n",
        "        국가별 타임존 오프셋 (단위: 일)\n",
        "        - 0: FOMC 발표 당일이 이벤트 day 0\n",
        "        - 1: FOMC 발표 다음날이 이벤트 day 0\n",
        "    event_window_days : int\n",
        "        이벤트 윈도우 길이 (기본 5일: day 0~4)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    DataFrame : NS Shock이 병합된 수익률 데이터\n",
        "        컬럼: datadate, country, return, benchmark_return, NS_shock, announcement_date, event_day\n",
        "    \"\"\"\n",
        "\n",
        "    merged_list = []\n",
        "\n",
        "    # 각 FOMC 발표에 대해 반복\n",
        "    for shock_idx, shock_row in shock_df.iterrows():\n",
        "        announcement = shock_row['datadate']\n",
        "        shock_val = shock_row['NS_shock'] if 'NS_shock' in shock_row else shock_row.iloc[1]\n",
        "\n",
        "        # print(f\"  처리중: {announcement.date()} - Shock: {shock_val:.4f}\")\n",
        "\n",
        "        # 각 국가별로 처리\n",
        "        for country, lag in time_lag_map.items():\n",
        "            # 해당 국가의 데이터 필터링\n",
        "            country_mask = (returns_df['country'] == country)\n",
        "            country_data = returns_df[country_mask].copy()\n",
        "\n",
        "            if len(country_data) == 0:\n",
        "                continue\n",
        "\n",
        "            # 이벤트 날짜 계산 (타임존 조정)\n",
        "            # lag=0: 발표 당일이 day 0\n",
        "            # lag=1: 발표 다음날이 day 0\n",
        "            event_date = announcement + pd.Timedelta(days=lag)\n",
        "\n",
        "            # 각 event day (0~4)에 대해 처리\n",
        "            for event_day in range(event_window_days):\n",
        "                window_date = event_date + pd.Timedelta(days=event_day)\n",
        "\n",
        "                # 해당 날짜의 거래일 찾기\n",
        "                window_data = country_data[country_data['datadate'] == window_date]\n",
        "\n",
        "                if not window_data.empty:\n",
        "                    # 여러 행이 있을 경우 첫 번째 행만 선택\n",
        "                    row = window_data.iloc[0].copy()\n",
        "                    row['NS_shock'] = shock_val\n",
        "                    row['announcement_date'] = announcement\n",
        "                    row['event_day'] = event_day\n",
        "                    merged_list.append(row)\n",
        "\n",
        "    if merged_list:\n",
        "        return pd.DataFrame(merged_list)\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "print(\"✓ 병합 함수 정의 완료\")\n",
        "\n",
        "# ====================================================================\n",
        "# STEP 4: 병합 실행\n",
        "# ====================================================================\n",
        "print(\"\\n[Step 4] 데이터 병합 실행 (이 과정은 시간이 걸릴 수 있습니다)...\")\n",
        "\n",
        "df_final = merge_shock_with_time_lag(\n",
        "    df_merged_clean,\n",
        "    nsshock,\n",
        "    country_time_lag,\n",
        "    event_window_days=5\n",
        ")\n",
        "\n",
        "print(f\"✓ 병합 완료: {len(df_final)} 행\")\n",
        "\n",
        "# ====================================================================\n",
        "# STEP 5: 최종 데이터 정리\n",
        "# ====================================================================\n",
        "print(\"\\n[Step 5] 최종 데이터 정리...\")\n",
        "\n",
        "# 컬럼 재정렬\n",
        "required_columns = ['announcement_date', 'datadate', 'event_day', 'country',\n",
        "                    'return', 'NS_shock']\n",
        "\n",
        "# df_merged_clean에 있는 모든 컬럼 보존\n",
        "available_cols = [col for col in required_columns if col in df_final.columns]\n",
        "other_cols = [col for col in df_final.columns if col not in required_columns]\n",
        "\n",
        "# 최종 컬럼 순서\n",
        "final_order = available_cols + other_cols\n",
        "df_final = df_final[final_order]\n",
        "\n",
        "# 타임스탬프 기준 정렬\n",
        "df_final = df_final.sort_values(['announcement_date', 'country', 'event_day']).reset_index(drop=True)\n",
        "\n",
        "print(f\"✓ 최종 컬럼 순서:\")\n",
        "print(df_final.columns.tolist())\n",
        "\n",
        "# ====================================================================\n",
        "# STEP 6: 데이터 확인 및 통계\n",
        "# ====================================================================\n",
        "print(\"\\n[Step 6] 데이터 확인...\")\n",
        "\n",
        "print(f\"\\n=== 최종 데이터셋 통계 ===\")\n",
        "print(f\"전체 관측치: {len(df_final)}\")\n",
        "print(f\"FOMC 발표 횟수: {df_final['announcement_date'].nunique()}\")\n",
        "print(f\"포함된 국가 수: {df_final['country'].nunique()}\")\n",
        "\n",
        "print(f\"\\n국가별 관측치 분포:\")\n",
        "print(df_final['country'].value_counts().head(15))\n",
        "\n",
        "print(f\"\\n이벤트 윈도우별 분포:\")\n",
        "print(df_final['event_day'].value_counts().sort_index())\n",
        "\n",
        "print(f\"\\n샘플 데이터 (첫 15행):\")\n",
        "print(df_final.head(15).to_string())\n",
        "\n",
        "# ====================================================================\n",
        "# STEP 7: 데이터 저장\n",
        "# ====================================================================\n",
        "print(\"\\n[Step 7] 데이터 저장...\")\n",
        "\n",
        "output_file = 'problem1_final_merged_data.csv'\n",
        "df_final.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"✓ 데이터 저장 완료: {output_file}\")\n",
        "print(f\"  파일 크기: {len(df_final)} 행, {len(df_final.columns)} 열\")\n",
        "\n",
        "# ====================================================================\n",
        "# STEP 8: 데이터 품질 확인\n",
        "# ====================================================================\n",
        "print(\"\\n[Step 8] 데이터 품질 확인...\")\n",
        "\n",
        "print(f\"\\n결측값 확인:\")\n",
        "print(df_final.isnull().sum())\n",
        "\n",
        "print(f\"\\n수익률(return) 기초통계:\")\n",
        "print(df_final['return'].describe())\n",
        "\n",
        "print(f\"\\nNS_shock 기초통계:\")\n",
        "print(df_final['NS_shock'].describe())\n",
        "\n",
        "# 저장된 파일 검증\n",
        "print(f\"\\n[최종 확인] 저장된 파일 검증...\")\n",
        "df_check = pd.read_csv(output_file)\n",
        "print(f\"✓ 저장 파일 확인: {len(df_check)} 행, {len(df_check.columns)} 열\")\n",
        "print(f\"✓ 컬럼명: {df_check.columns.tolist()}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"✓✓✓ PROBLEM 1 완성! ✓✓✓\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\n다음 단계:\")\n",
        "print(f\"- 이 데이터를 Problem 2(Event Study Design)에서 사용하세요\")\n",
        "print(f\"- 각 국가별로 비정상수익률(Abnormal Return) 계산\")\n",
        "print(f\"- 누적 비정상수익률(CAR) 계산\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDL-WC5OXMCN",
        "outputId": "53bf901c-bdf3-45c0-e7f8-f66647141146"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 1] 기존 데이터 불러오기...\n",
            "✓ df_merged_clean 데이터: 289503 행\n",
            "  컬럼: ['datadate', 'country', 'fic', 'n', 'currency', 'return', 'portret', 'portretx', 'prccd']\n",
            "✓ nsshock 데이터: 234 행\n",
            "    datadate  GSS_target  GSS_path      NS\n",
            "0 1995-02-01      0.0597    0.0268  0.0419\n",
            "1 1995-03-28      0.0258    0.0568  0.0288\n",
            "2 1995-05-23      0.0040   -0.0064  0.0009\n",
            "3 1995-07-06     -0.1033   -0.3785 -0.1510\n",
            "4 1995-08-22      0.0508    0.0217  0.0354\n",
            "\n",
            "[Step 2] 국가별 시차 정의...\n",
            "✓ 정의된 국가 수: 38\n",
            "\n",
            "[Step 3] 병합 함수 정의...\n",
            "✓ 병합 함수 정의 완료\n",
            "\n",
            "[Step 4] 데이터 병합 실행 (이 과정은 시간이 걸릴 수 있습니다)...\n",
            "✓ 병합 완료: 23222 행\n",
            "\n",
            "[Step 5] 최종 데이터 정리...\n",
            "✓ 최종 컬럼 순서:\n",
            "['announcement_date', 'datadate', 'event_day', 'country', 'return', 'NS_shock', 'fic', 'n', 'currency', 'portret', 'portretx', 'prccd']\n",
            "\n",
            "[Step 6] 데이터 확인...\n",
            "\n",
            "=== 최종 데이터셋 통계 ===\n",
            "전체 관측치: 23222\n",
            "FOMC 발표 횟수: 234\n",
            "포함된 국가 수: 38\n",
            "\n",
            "국가별 관측치 분포:\n",
            "country\n",
            "MEXICO            732\n",
            "BRAZIL            728\n",
            "AUSTRALIA         691\n",
            "UNITED KINGDOM    681\n",
            "NEW ZEALAND       677\n",
            "SWITZERLAND       675\n",
            "NORWAY            675\n",
            "SWEDEN            675\n",
            "DENMARK           674\n",
            "INDIA             668\n",
            "SINGAPORE         667\n",
            "PHILIPPINES       665\n",
            "SOUTH KOREA       663\n",
            "THAILAND          660\n",
            "POLAND            653\n",
            "Name: count, dtype: int64\n",
            "\n",
            "이벤트 윈도우별 분포:\n",
            "event_day\n",
            "0    7833\n",
            "1    7345\n",
            "2    2772\n",
            "3     451\n",
            "4    4821\n",
            "Name: count, dtype: int64\n",
            "\n",
            "샘플 데이터 (첫 15행):\n",
            "   announcement_date   datadate  event_day    country    return  NS_shock  fic     n currency   portret  portretx    prccd\n",
            "0         1995-02-01 1995-02-02          0  AUSTRALIA  0.004549    0.0597  AUS   192      AUD  0.010802  0.010802  1497.19\n",
            "1         1995-02-01 1995-02-03          1  AUSTRALIA  0.006359    0.0597  AUS   192      AUD -0.003422 -0.003576  1506.71\n",
            "2         1995-02-01 1995-02-06          4  AUSTRALIA  0.000996    0.0597  AUS   192      AUD  0.006739  0.006739  1508.21\n",
            "3         1995-02-01 1995-02-06          4      CHINA  0.000996    0.0597  CHN    17      CNY -0.047482 -0.047482  1508.21\n",
            "4         1995-02-01 1995-02-02          0    DENMARK  0.004549    0.0597  DNK    31      DKK  0.001325  0.001325  1497.19\n",
            "5         1995-02-01 1995-02-03          1    DENMARK  0.006359    0.0597  DNK    31      DKK -0.003482 -0.003482  1506.71\n",
            "6         1995-02-01 1995-02-06          4    DENMARK  0.000996    0.0597  DNK    31      DKK  0.000652  0.000652  1508.21\n",
            "7         1995-02-01 1995-02-03          1  HONG KONG  0.006359    0.0597  HKG    90      HKD  0.018158  0.018158  1506.71\n",
            "8         1995-02-01 1995-02-06          4  HONG KONG  0.000996    0.0597  HKG    90      HKD  0.055913  0.055913  1508.21\n",
            "9         1995-02-01 1995-02-02          0      INDIA  0.004549    0.0597  IND    51      INR  0.002237  0.002237  1497.19\n",
            "10        1995-02-01 1995-02-03          1      INDIA  0.006359    0.0597  IND    51      INR  0.004568  0.004568  1506.71\n",
            "11        1995-02-01 1995-02-06          4      INDIA  0.000996    0.0597  IND    51      INR -0.010315 -0.010315  1508.21\n",
            "12        1995-02-01 1995-02-03          1  INDONESIA  0.006359    0.0597  IDN    99      IDR  0.014371  0.014371  1506.71\n",
            "13        1995-02-01 1995-02-06          4  INDONESIA  0.000996    0.0597  IDN    99      IDR  0.014389  0.014382  1508.21\n",
            "14        1995-02-01 1995-02-02          0      JAPAN  0.004549    0.0597  JPN  1004      JPY -0.006077 -0.006077  1497.19\n",
            "\n",
            "[Step 7] 데이터 저장...\n",
            "✓ 데이터 저장 완료: problem1_final_merged_data.csv\n",
            "  파일 크기: 23222 행, 12 열\n",
            "\n",
            "[Step 8] 데이터 품질 확인...\n",
            "\n",
            "결측값 확인:\n",
            "announcement_date    0\n",
            "datadate             0\n",
            "event_day            0\n",
            "country              0\n",
            "return               0\n",
            "NS_shock             0\n",
            "fic                  0\n",
            "n                    0\n",
            "currency             0\n",
            "portret              0\n",
            "portretx             0\n",
            "prccd                0\n",
            "dtype: int64\n",
            "\n",
            "수익률(return) 기초통계:\n",
            "count    23222.000000\n",
            "mean         0.000212\n",
            "std          0.011122\n",
            "min         -0.044899\n",
            "25%         -0.005198\n",
            "50%          0.000324\n",
            "75%          0.005440\n",
            "max          0.085098\n",
            "Name: return, dtype: float64\n",
            "\n",
            "NS_shock 기초통계:\n",
            "count    23222.000000\n",
            "mean         0.000453\n",
            "std          0.036420\n",
            "min         -0.190100\n",
            "25%         -0.004100\n",
            "50%          0.002700\n",
            "75%          0.009300\n",
            "max          0.123800\n",
            "Name: NS_shock, dtype: float64\n",
            "\n",
            "[최종 확인] 저장된 파일 검증...\n",
            "✓ 저장 파일 확인: 23222 행, 12 열\n",
            "✓ 컬럼명: ['announcement_date', 'datadate', 'event_day', 'country', 'return', 'NS_shock', 'fic', 'n', 'currency', 'portret', 'portretx', 'prccd']\n",
            "\n",
            "======================================================================\n",
            "✓✓✓ PROBLEM 1 완성! ✓✓✓\n",
            "======================================================================\n",
            "\n",
            "다음 단계:\n",
            "- 이 데이터를 Problem 2(Event Study Design)에서 사용하세요\n",
            "- 각 국가별로 비정상수익률(Abnormal Return) 계산\n",
            "- 누적 비정상수익률(CAR) 계산\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRxFXYrQadAhq3gdReh5+4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}